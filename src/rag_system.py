from config.settings import settings
from src.document_loader import DocumentLoader
from src.vector_store import VectorStore
from src.llm_client import LlamaClient
from langchain_community.chat_message_histories import SQLChatMessageHistory
import pymysql
import os
from typing import List, Dict, Any, Optional

class RAGSystem:
    def __init__(self):
        self.document_loader = DocumentLoader(
            chunk_size=settings.CHUNK_SIZE,
            chunk_overlap=settings.CHUNK_OVERLAP
        )

        self.vector_store = VectorStore(
            db_path=settings.VECTOR_DB_PATH,
            embedding_model=settings.EMBEDDING_MODEL
        )

        self.llm_client = LlamaClient(
            model_name=settings.LLM_MODEL,
            base_url=settings.OLLAMA_BASE_URL
        )

        os.makedirs("data", exist_ok=True)
        self.memory_db_path = "sqlite:///data/memories.sqlite"

    def ingest_documents(self, directory_path: str = None):
        if directory_path is None:
            directory_path = settings.DOCUMENTS_PATH
        documents = self.document_loader.load_directory(directory_path)
        if documents:
            print("Adding documents to vector store...")
            self.vector_store.add_documents(documents)
            print("Document ingestion completed!")
        else:
            print("No documents found to ingest")

    def insert_message(self, session_id, role, content):
        conn = pymysql.connect(
            host='localhost', port=8889, user='root', password='root',
            database='ai_db', charset='utf8mb4'
        )
        try:
            with conn.cursor() as cursor:
                cursor.execute(
                    "INSERT INTO messages (session_id, role, content) VALUES (%s, %s, %s)",
                    (session_id, role, content)
                )
            conn.commit()
            return cursor.lastrowid
        finally:
            conn.close()

    def insert_file_meta(self, message_id, role, filepath, filename=None):
        conn = pymysql.connect(
            host='localhost', port=8889, user='root', password='root',
            database='ai_db', charset='utf8mb4'
        )
        try:
            with conn.cursor() as cursor:
                cursor.execute(
                    "INSERT INTO files (message_id, role, file, file_name, created_at) VALUES (%s, %s, %s, %s, NOW())",
                    (message_id, role, filepath, filename)
                )
            conn.commit()
            return cursor.lastrowid
        finally:
            conn.close()

    def query(
        self,
        question: str,
        session_id: str = "default",
        user_id: str = 'anonymouse',
        uploaded_docs: Optional[List[Dict[str, Any]]] = None
    ) -> dict:
        print(f"Processing query: {question}")

        use_memory = session_id != "default"
        memory = None
        history = []

        if use_memory:
            memory = SQLChatMessageHistory(
                connection=self.memory_db_path,
                session_id=session_id,
                table_name="message_store"
            )
            memory.add_user_message(question)
            msg_id_user = self.insert_message(session_id, "user", question)

            # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
            if uploaded_docs:
                for ud in uploaded_docs:
                    vpath = ud.get('filepath') or f"/uploads/{ud.get('filename','unknown')}"
                    self.insert_file_meta(msg_id_user, "user", vpath, ud.get('filename'))

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á history ‡πÉ‡∏´‡πâ LLM
            for msg in memory.messages:
                if msg.type == "human":
                    history.append({"role": "user", "content": msg.content})
                elif msg.type == "ai":
                    history.append({"role": "assistant", "content": msg.content})

        # ----- Retrieve ‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡πÇ‡∏ï‡∏£‡πå -----
                # ----- Retrieve ‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡πÇ‡∏ï‡∏£‡πå -----
        retrieved_docs = self.vector_store._enhanced_similarity_search(
            question,
            k=max(10, settings.TOP_K_RESULTS)  # ‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÄ‡∏¢‡∏≠‡∏∞‡∏Ç‡∏∂‡πâ‡∏ô‡∏ô‡∏¥‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡∏ó‡∏≤‡∏á rerank
        )

        # üîß ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì similarity (cosine) ‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ
        scored = []
        for d in retrieved_docs:
            dist = float(d.get('distance', 1.0))
            sim = 1.0 - dist
            d['similarity'] = sim
            # ‡∏ö‡∏≤‡∏á‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ 'rerank_score' ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≤‡∏Å cross-encoder
            d['rerank_score'] = float(d.get('rerank_score', 0.0))
            if sim >= 0.35:
                scored.append(d)

        if not scored:
            filtered_docs = []
        else:
            # ----- Adaptive threshold + similarity band -----
            scored.sort(key=lambda x: x['similarity'], reverse=True)
            best_sim = scored[0]['similarity']
            band = 0.08  # ‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ 0.06‚Äì0.12
            min_band_sim = max(0.40, best_sim - band)

            band_docs = [d for d in scored if d['similarity'] >= min_band_sim]

            # ----- Diversity by source (anti-duplicate) -----
            # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÅ‡∏´‡∏•‡πà‡∏á‡πÉ‡∏î‡πÅ‡∏´‡∏•‡πà‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Å‡∏¥‡∏ô‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
            max_per_source = 3
            picked = []
            per_source = {}
            for d in band_docs:
                meta = (d.get('metadata') or {})
                raw_src = meta.get('source') or d.get('source', '') or 'Unknown'
                src = str(raw_src).replace('\\', '/')
                if per_source.get(src, 0) < max_per_source:
                    picked.append(d)
                    per_source[src] = per_source.get(src, 0) + 1

            # ‡∏ñ‡πâ‡∏≤‡∏£‡∏ß‡∏°‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡∏•‡∏¥‡∏™‡∏ï‡πå‡πÄ‡∏î‡∏¥‡∏°
            need = max(settings.TOP_K_RESULTS, 6)
            if len(picked) < need:
                for d in scored:
                    if d in picked: 
                        continue
                    meta = (d.get('metadata') or {})
                    raw_src = meta.get('source') or d.get('source', '') or 'Unknown'
                    src = str(raw_src).replace('\\', '/')
                    if per_source.get(src, 0) < max_per_source:
                        picked.append(d)
                        per_source[src] = per_source.get(src, 0) + 1
                    if len(picked) >= need:
                        break

            # ----- Stitch by source (‡∏£‡∏ß‡∏°‡∏ä‡∏¥‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô) -----
            # ‡∏£‡∏ß‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ 1‚Äì3 ‡∏ä‡∏¥‡πâ‡∏ô‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
            from collections import defaultdict
            group = defaultdict(list)
            for d in picked:
                meta = (d.get('metadata') or {})
                raw_src = meta.get('source') or d.get('source', '') or 'Unknown'
                src = str(raw_src).replace('\\', '/')
                group[src].append(d)

            stitched_docs = []
            for src, items in group.items():
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° (rerank_score, similarity)
                items.sort(key=lambda x: (x.get('rerank_score', 0.0), x['similarity']), reverse=True)
                # ‡∏ï‡πà‡∏≠‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î N ‡∏ä‡∏¥‡πâ‡∏ô‡πÅ‡∏£‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡πá‡∏Å‡∏ã‡πå‡∏¢‡∏≤‡∏ß‡∏û‡∏≠ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô
                MAX_JOIN = 3
                MAX_CHARS = 1800
                contents = []
                total = 0
                take = 0
                for it in items:
                    c = (it.get('content') or '')
                    if not c:
                        continue
                    # ‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô
                    to_add = c[:MAX_CHARS - total]
                    if to_add.strip():
                        contents.append(to_add)
                        total += len(to_add)
                        take += 1
                    if take >= MAX_JOIN or total >= MAX_CHARS:
                        break
                if not contents:
                    continue

                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏ô‡∏ó‡∏£‡∏µ‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏ö‡∏ö stitched
                base = items[0]
                stitched_docs.append({
                    "content": "\n\n".join(contents),
                    "metadata": base.get('metadata') or {},
                    "distance": float(base.get('distance', 1.0)),
                    "similarity": float(base.get('similarity', 0.0)),
                    "rerank_score": float(base.get('rerank_score', 0.0)),
                    "source_key": src
                })

            # ----- Final rerank (‡∏≠‡∏≠‡∏õ‡∏ä‡∏±‡∏ô: ‡∏Å‡∏£‡∏ì‡∏µ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏£‡∏≠‡∏ö‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢) -----
            # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ cross-encoder ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô vector_store:
            try:
                ce = self.vector_store.rerank_model  # CrossEncoder ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß
                pairs = [(question, d['content']) for d in stitched_docs]
                if pairs:
                    scores = ce.predict(pairs)
                    for d, s in zip(stitched_docs, scores):
                        d['final_score'] = 0.5 * float(s) + 0.3 * d.get('similarity', 0.0) + 0.2 * max(0.0, 1.0 - float(d.get('distance', 1.0)))
                else:
                    for d in stitched_docs:
                        d['final_score'] = 0.3 * d.get('similarity', 0.0)
            except Exception:
                # fallback: ‡πÉ‡∏ä‡πâ similarity ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
                for d in stitched_docs:
                    d['final_score'] = 0.7 * d.get('similarity', 0.0) + 0.3 * max(0.0, 1.0 - float(d.get('distance', 1.0)))

            stitched_docs.sort(key=lambda x: x['final_score'], reverse=True)

            # ‡∏Ñ‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ LLM
            MAX_CONTEXT_BLOCKS = 6
            filtered_docs = stitched_docs[:MAX_CONTEXT_BLOCKS]


        # ‡πÅ‡∏ô‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î (‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î)
        if uploaded_docs:
            for ud in uploaded_docs:
                content = (ud.get("content") or "")
                if not content.strip():
                    continue
                filtered_docs.insert(0, {  # ‡∏î‡∏±‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô
                    "content": content[:4000],
                    "metadata": {
                        "source": f"Uploaded:{ud.get('filename','unknown')}",
                        "type": ud.get("kind", "upload"),
                        "role": "user"
                    },
                    "distance": 0.0,
                    "similarity": 1.0,
                    "final_score": 999.0
                })

        # ----- Guardrail: ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ï‡πà‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÄ‡∏î‡∏≤ -----
        avg_sim = sum(d.get('similarity', 0.0) for d in filtered_docs) / max(1, len(filtered_docs))
        avg_final = sum(d.get('final_score', 0.0) for d in filtered_docs) / max(1, len(filtered_docs))
        low_confidence = (avg_sim < 0.50) and (avg_final < 0.60)

        # ----- ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ö‡∏£‡∏¥‡∏ö‡∏ó -----
        answer = self.llm_client.generate_response(
            question if not low_confidence else f"""\
‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}

‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢:
- ‡∏´‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏î‡∏≤
- ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£" ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏ß‡πà‡∏≤‡∏Ç‡∏≤‡∏î‡∏≠‡∏∞‡πÑ‡∏£
""",
            filtered_docs,
            history=history if use_memory else None
        )

        # ----- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö + ‡πÑ‡∏ü‡∏•‡πå‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å assistant -----
        if use_memory and memory is not None:
            memory.add_ai_message(answer)
            msg_id_ai = self.insert_message(session_id, "assistant", answer)

            unique_sources = set()
            for doc in filtered_docs:
                meta = (doc.get('metadata') or {})
                role = (meta.get('role') or '').lower()
                if role == 'user':
                    continue  # ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á user

                raw_src = meta.get('source') or doc.get('source', '') or doc.get('source_key', '')
                link_src = (str(raw_src) or '').replace('\\', '/').replace('data/documents/', '/files/')
                if link_src and link_src not in unique_sources:
                    unique_sources.add(link_src)
                    self.insert_file_meta(msg_id_ai, "assistant", link_src, link_src.split('/')[-1])

        # ----- ‡∏™‡∏£‡πâ‡∏≤‡∏á sources ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö -----
        sources = []
        for doc in filtered_docs:
            meta = (doc.get('metadata') or {})
            role = (meta.get('role') or '').lower()
            if role == 'user':
                continue  # ‡πÑ‡∏°‡πà‡πÇ‡∏ä‡∏ß‡πå‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á

            raw_src = meta.get('source') or doc.get('source', '') or doc.get('source_key', '')
            link_src = (str(raw_src) or '').replace('\\', '/').replace('data/documents/', '/files/')

            sources.append({
                "source": link_src or "Unknown",
                "similarity": float(doc.get('similarity', 0.0)),
                "content_preview": (doc.get('content','')[:200] + "...") if doc.get('content') else ""
            })


        return {
            "answer": answer,
            "sources": sources,
            "retrieved_docs_count": len(filtered_docs)
        }

    def get_chat_history(self, session_id: str = "default") -> list:
        memory = SQLChatMessageHistory(
            connection=self.memory_db_path,
            session_id=session_id,
            table_name="message_store"
        )
        history = []
        for msg in memory.messages:
            history.append({
                "type": msg.type,
                "content": msg.content,
                "timestamp": getattr(msg, 'additional_kwargs', {}).get('timestamp', None)
            })
        return history

    def clear_chat_history(self, session_id: str = "default"):
        memory = SQLChatMessageHistory(
            connection=self.memory_db_path,
            session_id=session_id,
            table_name="message_store"
        )
        memory.clear()
        print(f"Chat history for session '{session_id}' cleared!")

    def get_system_info(self):
        return {
            "vector_store": self.vector_store.get_collection_info(),
            "embedding_model": settings.EMBEDDING_MODEL,
            "llm_model": settings.LLM_MODEL,
            "memory_db": self.memory_db_path
        }
    
